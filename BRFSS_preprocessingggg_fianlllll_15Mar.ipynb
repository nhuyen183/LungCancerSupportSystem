{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QgiznxMrt7FNMiBrsW6duF1SsDt_Y02k",
      "authorship_tag": "ABX9TyO6ERfsyawOmdLzG6mN74G9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhuyen183/LungCancerSupportSystem/blob/master/BRFSS_preprocessingggg_fianlllll_15Mar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UxvbCvWzF2iN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77ae001-bc07-4c57-ec60-23d029692923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/114 kB 12%] [Waiting for headers]\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r0% [3 InRelease 14.2 kB/114 kB 12%] [2 InRelease 20.0 kB/114 kB 18%] [Waiting f\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [3 InRelease 15.6 kB/114 kB 14%] [2 InRelease 43.1 kB/114 kB 38%] [Waiting f\r0% [3 InRelease 67.8 kB/114 kB 60%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r                                                                    \rGet:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "\r0% [5 InRelease 4,051 B/108 kB 4%] [Waiting for headers] [Waiting for headers]\r                                                                              \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [5 InRelease 25.8 kB/108 kB 24%] [Waiting for headers] [Waiting for headers]\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,544 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,019 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,312 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,397 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,136 kB]\n",
            "Fetched 10.8 MB in 4s (2,759 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "#@title Installing Spark and dependencies\n",
        "#Java 8\n",
        "#Apache Spark with hadoop and\n",
        "#Findspark (used to locate the spark in the system)\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "#Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Define the problem\n",
        "What sorts of people were likely to have lung cancer?"
      ],
      "metadata": {
        "id": "yZQ9Ioxnrn8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Gather the data\n",
        "The datasets can be found here:\n",
        "* https://www.kaggle.com/datasets/aemreusta/brfss-2020-survey-data\n",
        "* https://www.kaggle.com/datasets/sakinak/behavioral-risk-factor-surveillance-survey-201619"
      ],
      "metadata": {
        "id": "bc9uZc0_r0rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Spark entry points\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "c6udoYI94hjI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext(conf=SparkConf())\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "metadata": {
        "id": "UJAvHSw3_PY2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Spark Mlib libraries\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import OneVsRest"
      ],
      "metadata": {
        "id": "7U1wvI6hSJ1m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Prepare data for consumption"
      ],
      "metadata": {
        "id": "Iqd2fYf8sANz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount content to drive for kaggle data download\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f0oAl82IKAKf",
        "outputId": "b7488e76-b9db-4639-94a7-303f887f0f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "TKKEiZnQ_Opq",
        "outputId": "dcb363fe-ea4d-4f1a-d637-4ba0e949648c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "HMOTjRHtKNzH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "iZsjMEFPMwt0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "1hVTxodyKaZn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download aemreusta/brfss-2020-survey-data"
      ],
      "metadata": {
        "id": "iwQZmM_OLlfi",
        "outputId": "e7acc09c-66f4-41a5-8c32-d847b87d4ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brfss-2020-survey-data.zip to /content\n",
            " 87% 42.0M/48.3M [00:00<00:00, 69.5MB/s]\n",
            "100% 48.3M/48.3M [00:00<00:00, 76.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download sakinak/behavioral-risk-factor-surveillance-survey-201619"
      ],
      "metadata": {
        "id": "B3TqFy7SlblE",
        "outputId": "38bc0941-e728-4b2f-f050-6e2a9e2a571b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading behavioral-risk-factor-surveillance-survey-201619.zip to /content\n",
            " 96% 225M/234M [00:01<00:00, 142MB/s]\n",
            "100% 234M/234M [00:01<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Agbrey1YNwLx",
        "outputId": "89e7542d-4278-4efb-f1b6-52d5ba431ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "behavioral-risk-factor-surveillance-survey-201619.zip\n",
            "brfss-2020-survey-data.zip\n",
            "drive\n",
            "sample_data\n",
            "spark-3.1.1-bin-hadoop3.2\n",
            "spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip brfss-2020-survey-data.zip"
      ],
      "metadata": {
        "id": "iOsR2nmcOFtl",
        "outputId": "e7095fe3-2d36-4f24-b562-7bd14aec005a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  brfss-2020-survey-data.zip\n",
            "  inflating: brfss2020.csv           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip behavioral-risk-factor-surveillance-survey-201619.zip"
      ],
      "metadata": {
        "id": "tHtnFSMplmq6",
        "outputId": "8c9f2ae3-fdee-4e10-f4f7-daeeb12ab9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  behavioral-risk-factor-surveillance-survey-201619.zip\n",
            "  inflating: 2016.csv                \n",
            "  inflating: 2017.csv                \n",
            "  inflating: 2018.csv                \n",
            "  inflating: 2019.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import check_output\n",
        "print('-'*10, 'Files', '-'*10)\n",
        "print(check_output(['ls', './']).decode('utf8'))"
      ],
      "metadata": {
        "id": "Hay7kOmrSQU6",
        "outputId": "5f24b6d6-f9ab-41ac-f0ac-6f21d5a9698b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Files ----------\n",
            "2016.csv\n",
            "2017.csv\n",
            "2018.csv\n",
            "2019.csv\n",
            "behavioral-risk-factor-surveillance-survey-201619.zip\n",
            "brfss2020.csv\n",
            "brfss-2020-survey-data.zip\n",
            "drive\n",
            "sample_data\n",
            "spark-3.1.1-bin-hadoop3.2\n",
            "spark-3.1.1-bin-hadoop3.2.tgz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the BRFSS dataset and Prediction task\n",
        "\n",
        "The Behavioral Risk Factor Surveillance System (BRFSS) is a collaborative project between all of the states in the United States and participating US territories and the Centers for Disease Control and Prevention (CDC).\n",
        "\n",
        "BRFSS’s objective is to collect uniform state-specific data on health risk behaviors, chronic diseases and conditions, access to health care, and use of preventive health services related to the leading causes of death and disability in the United States. BRFSS conducts both landline and mobile phone-based surveys with individuals over the age of 18. General factors assessed by the BRFSS in 2020 included health status and healthy days, exercise, insufficient sleep, chronic health conditions, oral health, tobacco use, cancer screenings, and access to healthcare.\n",
        "\n",
        "The aim of this project is to build a model with relatively high accuracy and AUC that could serve as an decision aid for those at high risk of developing lung cancer.\n",
        "\n",
        "The data contains information about 401958 unique survey participant. As a result of my research to select the ones related to coronary artery disease among a total of 279 different features. Each example in the dataset contains the following demographic data for a set of individuals\n",
        "\n",
        "### Categorical Features\n",
        "*   `_AGE65YR`: The age of the individual in years two-level categories `18 <= AGE <= 64`: `1` and `65 <= AGE <= 99`:`2`\n",
        "*   `SEXVAR`: Sex of Respondent `Male: 1` and `Female: 2`\n",
        "*   `_BMI5CAT`:  Four-categories of Body Mass Index (BMI)`_BMI5 < 1850: Underweight` ; `1850 <= _BMI5 < 2500: Normal`;`2500 <= _BMI5 < 3000: Overweight`;`3000 <= _BMI5 < 9999: Obese`\n",
        "*   `GENHLTH`: Health status: Would you say that in general your health is: `1: Excellent`; `2: Very good` ; `3: Good` ; `4: Fair` ; `5: Poor`\n",
        "*   `SMOKE100`: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] `1: Yes` ; `2: No`\n",
        "*   `_SMOKER3`: Four-level smoker status: Everyday smoker: `1`, Someday smoker: `2`, Former smoker: `3`, Non-smoker: `4`\n",
        "\n",
        "### Lung Cancer (Features) Screening Section\n",
        "*   `LCSFIRST`: How old were you when you first started to smoke cigarettes regularly. `Value 1-100 in years`\n",
        "*   `LCSLAST`: How old were you when you last smoked cigarettes regularly? `Value 1-100 in years`\n",
        "*   `LCSNUMCG`: On average, when you smoke/smoked regularly, about how many cigarettes do/did you usually smoke each \n",
        "day? `Value 1-300 in number of cigarettes`\n",
        "*   `LCSCTSCN`: In the last 12 months, did you have a CT or CAT scan? Example include: `Yes, to check for lung cancer`, `No (did not have a CT scan`, `Had a CT scan, but for other reason`.\n",
        "*   `CNCRTYP1`:  What type of cancer was it? (If Response = 2 (Two) or 3 (Three or more), ask: “With your most recent \n",
        "diagnoses of cancer, what type of cancer was it?”). Examples include: `Lung cancer: 24`, `Others: 1-30`\n",
        "*   `STOPSMK2`:  During the past 12 months, have you stopped smoking for one day or longer because you were trying to quit smoking? `Yes: 1` or `No: 2`.\n",
        "*   `ECIGARET`: Have you ever used an e-cigarette or other electronic vaping product, even just one time, in your entire life? `Yes: 1` or `No: 2`.\n",
        "*   `ECIGNOW`: Do you now use e-cigarettes or other electronic vaping products every day, some days, or not at all? `Every day: 1`; `Some days: 2` or `Not at all: 3`\n",
        "* `ASTHMA3`: (Ever told) (you had) asthma? `Yes: 1` or `No: 2`.\n",
        "### Prediction Task\n",
        "The prediction task is to **early predict whether a person have the high risk of lung cancer.**\n",
        "\n",
        "### Label\n",
        "*   `CNCRTYP1`: What type of cancer (lung cancer = 24)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FU9ICs1C3_i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "from google.colab import widgets\n",
        "# For facets\n",
        "from IPython.core.display import display, HTML\n",
        "import base64\n",
        "!pip install facets-overview==1.0.0\n",
        "from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator"
      ],
      "metadata": {
        "id": "AIaSSnM5G8kt",
        "outputId": "a876e919-7dd4-4287-9194-b2b15ed6fd54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facets-overview==1.0.0\n",
            "  Downloading facets_overview-1.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.9/dist-packages (from facets-overview==1.0.0) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from facets-overview==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from facets-overview==1.0.0) (3.19.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.22.0->facets-overview==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.22.0->facets-overview==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.22.0->facets-overview==1.0.0) (1.15.0)\n",
            "Installing collected packages: facets-overview\n",
            "Successfully installed facets-overview-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load packages\n",
        "import sys\n",
        "print('Python version: {}'. format(sys.version))\n",
        "\n",
        "import pandas as pd\n",
        "print('Python version: {}'. format(pd.__version__))\n",
        "\n",
        "import matplotlib\n",
        "print('matplotlib version: {}'. format(matplotlib.__version__))\n",
        "\n",
        "import numpy as np\n",
        "print('numpy version: {}'. format(np.__version__))\n",
        "\n",
        "import scipy as sp\n",
        "print('scipy version: {}'. format(sp.__version__))\n",
        "\n",
        "import IPython\n",
        "from IPython import display # pretty printing of dataframe in Jupyter notebook\n",
        "print('IPython version: {}'. format(IPython.__version__))\n",
        "\n",
        "import pyspark\n",
        "print('Apache Spark Pyspark version: {}'. format(pyspark.__version__)) # pyspark version\n",
        "\n",
        "# misc libraries\n",
        "import random\n",
        "import time\n",
        "\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print('-'*25)"
      ],
      "metadata": {
        "id": "4SvIs_HXORO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9658dfbb-535d-4d1b-d311-28a02b0980cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n",
            "Python version: 1.4.4\n",
            "matplotlib version: 3.5.3\n",
            "numpy version: 1.22.4\n",
            "scipy version: 1.10.1\n",
            "IPython version: 7.9.0\n",
            "Apache Spark Pyspark version: 3.1.1\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "data_2020 = spark.read.csv('./brfss2020.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2020.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "es2VmY2VSUD9",
        "outputId": "bb304a3a-25c8-4f8b-f0ec-e67793f9ab46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- data types ----------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0       1\n",
              "0      _STATE  double\n",
              "1      FMONTH  double\n",
              "2       IDATE     int\n",
              "3      IMONTH     int\n",
              "4        IDAY     int\n",
              "..        ...     ...\n",
              "274  _STOLDNA  double\n",
              "275  _VIRCOLN  double\n",
              "276  _SBONTIM  double\n",
              "277  _CRCREC1  double\n",
              "278  _AIDTST4  double\n",
              "\n",
              "[279 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-494bc15a-12b9-4098-b087-de910e1cb7ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_STATE</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FMONTH</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IDATE</td>\n",
              "      <td>int</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMONTH</td>\n",
              "      <td>int</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IDAY</td>\n",
              "      <td>int</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>_STOLDNA</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>_VIRCOLN</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>_SBONTIM</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>_CRCREC1</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>_AIDTST4</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>279 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-494bc15a-12b9-4098-b087-de910e1cb7ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-494bc15a-12b9-4098-b087-de910e1cb7ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-494bc15a-12b9-4098-b087-de910e1cb7ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F = data_2020.select('SEXVAR', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'SMOKE100', '_SMOKER3',\n",
        "                              'CHECKUP1', #frequency of checkup\n",
        "                              'EXERANY2', #Exercise in Past 30 Days\n",
        "                              'LASTSMK2',#time since quitting\n",
        "                              'CVDSTRK3', #ever had a stroke\n",
        "                              'CVDCRHD4', #Ever Diagnosed with Angina or Coronary Heart Disease\n",
        "                  'LCSFIRST', 'LCSLAST', 'LCSNUMCG', \n",
        "                  'LCSCTSCN',\n",
        "                  'CNCRTYP1',\n",
        "                   'ASTHMA3', 'CHCCOPD2', 'ECIGARET','STOPSMK2')#, 'ECIGNOW')\n",
        "data_2020F.show()"
      ],
      "metadata": {
        "id": "a59eVrl_rXpD",
        "outputId": "cc2b6bb6-a3b8-4767-f2d7-2050e6ce6dbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+-------+--------+--------+--------+\n",
            "|SEXVAR|_AGE65YR|_BMI5CAT|GENHLTH|SMOKE100|_SMOKER3|CHECKUP1|EXERANY2|LASTSMK2|CVDSTRK3|CVDCRHD4|LCSFIRST|LCSLAST|LCSNUMCG|LCSCTSCN|CNCRTYP1|ASTHMA3|CHCCOPD2|ECIGARET|STOPSMK2|\n",
            "+------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+-------+--------+--------+--------+\n",
            "|   2.0|     1.0|     1.0|    2.0|     1.0|     1.0|     4.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    1.0|     1.0|     1.0|     2.0|\n",
            "|   2.0|     2.0|     3.0|    3.0|    null|     9.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    1.0|     2.0|    null|    null|\n",
            "|   2.0|     2.0|    null|    3.0|     2.0|     4.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|    null|    1.0|     2.0|     4.0|     2.0|     2.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     2.0|    2.0|     2.0|     4.0|     1.0|     1.0|    null|     1.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   1.0|     2.0|     3.0|    4.0|     1.0|     3.0|     2.0|     1.0|     6.0|     2.0|     2.0|    null|   null|    null|    null|    null|    1.0|     1.0|     1.0|    null|\n",
            "|   2.0|     2.0|     2.0|    3.0|     2.0|     4.0|     1.0|     2.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     3.0|    4.0|     1.0|     1.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|    null|     2.0|\n",
            "|   2.0|     1.0|     2.0|    2.0|     2.0|     4.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     3.0|    4.0|     1.0|     3.0|     1.0|     2.0|     7.0|     2.0|     1.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     2.0|    4.0|     2.0|     4.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    1.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     4.0|    3.0|     1.0|     3.0|     1.0|     2.0|     7.0|     2.0|     2.0|    null|   null|    null|    null|    null|    1.0|     1.0|     2.0|    null|\n",
            "|   2.0|     2.0|    null|    2.0|    null|     9.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|    null|    null|\n",
            "|   2.0|     2.0|     3.0|    4.0|     2.0|     4.0|     1.0|     2.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   1.0|     2.0|     4.0|    3.0|     2.0|     4.0|     1.0|     1.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   1.0|     1.0|     4.0|    5.0|     1.0|     1.0|     1.0|     2.0|    null|     2.0|     1.0|    null|   null|    null|    null|    null|    1.0|     1.0|     2.0|     1.0|\n",
            "|   2.0|     1.0|     3.0|    2.0|     1.0|     3.0|     1.0|     1.0|     7.0|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   1.0|     2.0|     3.0|    2.0|     1.0|     3.0|     1.0|     1.0|     7.0|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     2.0|     2.0|    null|\n",
            "|   2.0|     2.0|     3.0|    3.0|     2.0|     4.0|     1.0|     2.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     1.0|     2.0|    null|\n",
            "|   2.0|     1.0|     3.0|    3.0|     1.0|     1.0|     1.0|     2.0|    null|     2.0|     2.0|    null|   null|    null|    null|    null|    2.0|     1.0|     2.0|     1.0|\n",
            "+------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+-------+--------+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2020F.select([eval('data_2020F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2020F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "VIXjj0pdAXSt",
        "outputId": "baa759a2-8101-49b0-c85d-2b81010d39ff"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with null values:\n",
            "-------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sum(SEXVAR)  sum(_AGE65YR)  sum(_BMI5CAT)  sum(GENHLTH)  sum(SMOKE100)  \\\n",
              "0            0              0          41350             0          17854   \n",
              "\n",
              "   sum(_SMOKER3)  sum(CHECKUP1)  sum(EXERANY2)  sum(LASTSMK2)  sum(CVDSTRK3)  \\\n",
              "0              0              0              0         298221              0   \n",
              "\n",
              "   sum(CVDCRHD4)  sum(LCSFIRST)  sum(LCSLAST)  sum(LCSNUMCG)  sum(LCSCTSCN)  \\\n",
              "0              0         387902        388320         388339         370699   \n",
              "\n",
              "   sum(CNCRTYP1)  sum(ASTHMA3)  sum(CHCCOPD2)  sum(ECIGARET)  sum(STOPSMK2)  \n",
              "0         379270             0              0         137388         349524  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d5670af-0aaf-4576-b675-2458e7ff1064\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum(SEXVAR)</th>\n",
              "      <th>sum(_AGE65YR)</th>\n",
              "      <th>sum(_BMI5CAT)</th>\n",
              "      <th>sum(GENHLTH)</th>\n",
              "      <th>sum(SMOKE100)</th>\n",
              "      <th>sum(_SMOKER3)</th>\n",
              "      <th>sum(CHECKUP1)</th>\n",
              "      <th>sum(EXERANY2)</th>\n",
              "      <th>sum(LASTSMK2)</th>\n",
              "      <th>sum(CVDSTRK3)</th>\n",
              "      <th>sum(CVDCRHD4)</th>\n",
              "      <th>sum(LCSFIRST)</th>\n",
              "      <th>sum(LCSLAST)</th>\n",
              "      <th>sum(LCSNUMCG)</th>\n",
              "      <th>sum(LCSCTSCN)</th>\n",
              "      <th>sum(CNCRTYP1)</th>\n",
              "      <th>sum(ASTHMA3)</th>\n",
              "      <th>sum(CHCCOPD2)</th>\n",
              "      <th>sum(ECIGARET)</th>\n",
              "      <th>sum(STOPSMK2)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41350</td>\n",
              "      <td>0</td>\n",
              "      <td>17854</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>298221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>387902</td>\n",
              "      <td>388320</td>\n",
              "      <td>388339</td>\n",
              "      <td>370699</td>\n",
              "      <td>379270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>137388</td>\n",
              "      <td>349524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d5670af-0aaf-4576-b675-2458e7ff1064')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d5670af-0aaf-4576-b675-2458e7ff1064 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d5670af-0aaf-4576-b675-2458e7ff1064');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.filter(data_2020F.CNCRTYP1 ==24.0).count()"
      ],
      "metadata": {
        "id": "B4WvXkivYdxz",
        "outputId": "b8368a22-20f6-4fb3-d285-18a46d747748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.count()"
      ],
      "metadata": {
        "id": "oJ69yRpnUyKz",
        "outputId": "e0053504-75c6-40bd-abef-954d5d5cb54c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "401958"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#401958\n",
        "data_2020F = data_2020F.na.drop(how='any', thresh=None, subset=( \"GENHLTH\", \"CHECKUP1\", \"EXERANY2\", \"CVDSTRK3\", \"CVDCRHD4\", \"CHCCOPD2\"))#\"_BMI5CAT\",, \"ASTHMA3\", \"CHCCOPD2\", \"LCSFIRST\",\"LCSLAST\",\"LCSNUMCG\",\"LCSCTSCN\", \"LASTSMK2\", \"STOPSMK2\", \"ECIGNOW\"))\n",
        "data_2020F.count()"
      ],
      "metadata": {
        "id": "PhbNw7X-Uj9A",
        "outputId": "66a85f4c-e08f-4960-cedf-2a08862d74f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "401946"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2020F = data_2020F.withColumn(\"SEXVAR\", col('SEXVAR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHECKUP1\", col('CHECKUP1').cast(IntegerType()))\\\n",
        "          .withColumn(\"EXERANY2\", col('EXERANY2').cast(IntegerType()))\\\n",
        "          .withColumn(\"LASTSMK2\", col('LASTSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDSTRK3\", col('CVDSTRK3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDCRHD4\", col('CVDCRHD4').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSFIRST\", col('LCSFIRST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSLAST\", col('LCSLAST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSNUMCG\", col('LCSNUMCG').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "                    .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CHCCOPD2\", col('CHCCOPD2').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\n",
        "                    #.withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "UHcJLziUEndi"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.printSchema"
      ],
      "metadata": {
        "id": "R-U64hlaC_Yi",
        "outputId": "7721bd2b-f3ee-45fe-db7d-b5ee1ca23306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.printSchema of DataFrame[SEXVAR: int, _AGE65YR: int, _BMI5CAT: int, GENHLTH: int, SMOKE100: int, _SMOKER3: int, CHECKUP1: int, EXERANY2: int, LASTSMK2: int, CVDSTRK3: int, CVDCRHD4: int, LCSFIRST: int, LCSLAST: int, LCSNUMCG: int, LCSCTSCN: int, CNCRTYP1: int, ASTHMA3: int, CHCCOPD2: int, ECIGARET: int, STOPSMK2: int]>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: 1 if y == 24 else 0, StringType())\n",
        "\n",
        "x_age = udf(lambda x: 0 if (x==1 or x==3) else 1, StringType())\n",
        "x_bmi = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4) else 2, StringType())\n",
        "x_smoke3 = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4) else 4, StringType())\n",
        "x_agefirst = udf(lambda x: 0 if (x==777 or x==999) else x, IntegerType())#null==0\n",
        "x_agelast = udf(lambda x: 0 if (x==777 or x==999) else x, IntegerType())\n",
        "x_numcig = udf(lambda x: 0 if (x==777 or x==999) else x, IntegerType())\n",
        "x_CT = udf(lambda x: x if (x==1 or x==3) else 0, StringType())\n",
        "x_ecig = udf(lambda x: x if (x==1 or x==2 or x==3) else 3, StringType())\n",
        "x_health = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4 or x==5) else 3, StringType())\n",
        "x_bool = udf(lambda x: 1 if (x==1) else 0, StringType())\n",
        "\n",
        "processed_2020 = data_2020F.withColumn(\"Gender\", x_bool('SEXVAR')).drop(\"SEXVAR\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"FirstSmokedAge\", x_agefirst('LCSFIRST')).drop(\"LCSFIRST\")\\\n",
        "                    .withColumn(\"LastSmokedAge\", x_agelast('LCSLAST')).drop(\"LCSLAST\")\\\n",
        "                    .withColumn(\"AvgNumCigADay\", x_numcig('LCSNUMCG')).drop(\"LCSNUMCG\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD2')).drop(\"CHCCOPD2\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "eDAVhS70Eyfx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.show()"
      ],
      "metadata": {
        "id": "uzq9-ilF8ydD",
        "outputId": "ac9e731b-116e-4f8f-d636-9396038938de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7f0869a0c3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020 "
      ],
      "metadata": {
        "id": "JPHiGP__GQN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "RQLWe9R0FcXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020 = imputer.fit(processed_2020).transform(processed_2020)"
      ],
      "metadata": {
        "id": "p5wiIyQSKHcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.show(5)"
      ],
      "metadata": {
        "id": "Mrza-rVrKgen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "47G5jrzjJvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.write.option(\"header\",True).csv(\"data2020\")"
      ],
      "metadata": {
        "id": "4_Xbra22ND2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.groupBy(processed_2020.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "flLjDFqKFksT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 2\n",
        "data_2017 = spark.read.csv('./2017.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2017.dtypes)"
      ],
      "metadata": {
        "id": "fpqW-agTF9SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2017F = data_2017.select('SEX', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'SMOKE100', '_SMOKER3',\n",
        "                  'LCSFIRST', 'LCSLAST', 'LCSNUMCG', 'LCSCTSCN', 'CNCRTYP1',\n",
        "                  'STOPSMK2', 'ASTHMA3', 'CHCCOPD1', 'ECIGARET',  'ECIGNOW')\n",
        "data_2017F.show(6)"
      ],
      "metadata": {
        "id": "6y-28e5EF9SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#401958\n",
        "data_2017F = data_2017F.na.drop(how=\"any\")\n",
        "data_2017F.count()"
      ],
      "metadata": {
        "id": "7EY6U960F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2017F = data_2017F.withColumn(\"SEX\", col('SEX').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSFIRST\", col('LCSFIRST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSLAST\", col('LCSLAST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSNUMCG\", col('LCSNUMCG').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "                    .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CHCCOPD1\", col('CHCCOPD1').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "K3swrzG6F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2017F.select([eval('data_2017F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2017F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "aV_J-yJ1F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2017F.printSchema()"
      ],
      "metadata": {
        "id": "v4xWm_D-F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: 1 if y == 24 else 0, StringType())\n",
        "\n",
        "processed_2017 = data_2017F.withColumn(\"Gender\", x_bool('SEX')).drop(\"SEX\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"FirstSmokedAge\", x_agefirst('LCSFIRST')).drop(\"LCSFIRST\")\\\n",
        "                    .withColumn(\"LastSmokedAge\", x_agelast('LCSLAST')).drop(\"LCSLAST\")\\\n",
        "                    .withColumn(\"AvgNumCigADay\", x_numcig('LCSNUMCG')).drop(\"LCSNUMCG\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD1')).drop(\"CHCCOPD1\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "aptggGVK2mfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.show()"
      ],
      "metadata": {
        "id": "zYOHNjzL2l84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "rm7sLfzm3DHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017 = imputer.fit(processed_2017).transform(processed_2017)"
      ],
      "metadata": {
        "id": "zpynWheN3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.show(5)"
      ],
      "metadata": {
        "id": "kY2lqtf73DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "eWutDHdG3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.groupBy(processed_2017.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "Wfm7DEwC3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 3\n",
        "data_2018 = spark.read.csv('./2018.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2018.dtypes)"
      ],
      "metadata": {
        "id": "OV3SzAuNI6qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F = data_2018.select('SEX1', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'SMOKE100', '_SMOKER3',\n",
        "                  'LCSFIRST', 'LCSLAST', 'LCSNUMCG', 'LCSCTSCN', 'CNCRTYP1',\n",
        "                  'STOPSMK2', 'ASTHMA3', 'CHCCOPD1', 'ECIGARET',  'ECIGNOW')\n",
        "data_2018F.show(6)"
      ],
      "metadata": {
        "id": "KvRzP3z5I6rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2018F = data_2018F.withColumn(\"SEX1\", col('SEX1').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSFIRST\", col('LCSFIRST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSLAST\", col('LCSLAST').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSNUMCG\", col('LCSNUMCG').cast(IntegerType()))\\\n",
        "                    .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "                    .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CHCCOPD1\", col('CHCCOPD1').cast(IntegerType()))\\\n",
        "                    .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\\\n",
        "                    .withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "coDyK_iDbIyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2018F.select([eval('data_2018F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2018F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "C6d0Yio_I6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.printSchema()"
      ],
      "metadata": {
        "id": "2-k2n0j03_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: 1 if y == 24 else 0, StringType())\n",
        "\n",
        "processed_2018 = data_2018F.withColumn(\"Gender\", x_bool('SEX1')).drop(\"SEX1\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"FirstSmokedAge\", x_agefirst('LCSFIRST')).drop(\"LCSFIRST\")\\\n",
        "                    .withColumn(\"LastSmokedAge\", x_agelast('LCSLAST')).drop(\"LCSLAST\")\\\n",
        "                    .withColumn(\"AvgNumCigADay\", x_numcig('LCSNUMCG')).drop(\"LCSNUMCG\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD1')).drop(\"CHCCOPD1\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "sUNNNGf13_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.show()"
      ],
      "metadata": {
        "id": "BWSEGR2p3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "pl69LlHc3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018 = imputer.fit(processed_2018).transform(processed_2018)"
      ],
      "metadata": {
        "id": "TWRpizsx3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.show(5)"
      ],
      "metadata": {
        "id": "y5RX2PWp3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "matqeC9s3_MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.groupBy(processed_2017.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "8fRbxoZG3_MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#437436\n",
        "data_2018F = data_2018F.na.drop(how=\"any\")\n",
        "data_2018F.count()"
      ],
      "metadata": {
        "id": "4NPPejlaI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.show(6)"
      ],
      "metadata": {
        "id": "dpZZLsdHI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.groupBy(data_2018F.CNCRTYP1).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "Y6WQEJZZI6rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data_2018F.filter(data_2018F.CNCRTYP1 == 24)\n",
        "test_data.show()"
      ],
      "metadata": {
        "id": "nfJJf0ejI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "data = processed_2017.unionByName(processed_2018)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data.dtypes)"
      ],
      "metadata": {
        "id": "8oWD6CAk4exO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupBy(data.HasLungCancer).count().show()\n"
      ],
      "metadata": {
        "id": "YAFMFMlM4wYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.write.option(\"header\",True).csv(\"data201718\")"
      ],
      "metadata": {
        "id": "5Nbsbtbj4XOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 4\n",
        "data_2019 = spark.read.csv('./2019.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2019.dtypes)"
      ],
      "metadata": {
        "id": "a0GVWDOuJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F = data_2019.select('SEXVAR', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'SMOKE100', '_SMOKER3',\n",
        "                  'LCSFIRST', 'LCSLAST', 'LCSNUMCG', 'LCSCTSCN', 'CNCRTYP1',\n",
        "                  'STOPSMK2', 'ASTHMA3', 'CHCCOPD2') #'ECIGARET',  'ECIGNOW'\n",
        "data_2019F.show(6)"
      ],
      "metadata": {
        "id": "3qoKhmNjJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2019F.select([eval('data_2019F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2019F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "xgu2EkJ6J1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F = data_2019F.na.drop(how=\"any\")\n",
        "data_2019F.count()"
      ],
      "metadata": {
        "id": "7LNr5x_LJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.show(6)"
      ],
      "metadata": {
        "id": "_Pi8ZvtuJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.filter(data_2019F.CNCRTYP1 != 'NA').count()"
      ],
      "metadata": {
        "id": "p7YlFDENJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.printSchema()"
      ],
      "metadata": {
        "id": "rNFFkz0uJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: '1' if y == '24' else '0', StringType())\n",
        "x_udf = udf(lambda x: '0' if (x=='NA' or x=='7' or x=='77' or x=='777' or x=='9' or x=='99' or x=='888' or x=='999') else x, StringType())\n",
        "\n",
        "processed_2019 = data_2019F.withColumn(\"Gender\", x_udf('SEXVAR')).drop(\"SEXVAR\")\\\n",
        "                    .withColumn(\"Age65\", x_udf('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_udf('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"Smoked100\", x_udf('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_udf('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"FirstSmokedAge\", x_udf('LCSFIRST')).drop(\"LCSFIRST\")\\\n",
        "                    .withColumn(\"LastSmokedAge\", x_udf('LCSLAST')).drop(\"LCSLAST\")\\\n",
        "                    .withColumn(\"AvgNumCigADay\", x_udf('LCSNUMCG')).drop(\"LCSNUMCG\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_udf('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_udf('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_udf('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_udf('CHCCOPD2')).drop(\"CHCCOPD2\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "AeHO0eHqJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2019.printSchema()"
      ],
      "metadata": {
        "id": "d6_5G06bJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2019.groupBy(processed_2019.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "398LfjydJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "data = processed_2020.unionByName(processed_2017)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data.dtypes)"
      ],
      "metadata": {
        "id": "9Wj7XDTzpcfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw = data.unionByName(processed_2018)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_raw.dtypes)"
      ],
      "metadata": {
        "id": "EtwRGyl3R_hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define schema explitcitly\n",
        "from pyspark.sql.types import *\n",
        "data_raw.columns"
      ],
      "metadata": {
        "id": "w2lEu1Bt9e0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.groupBy(data_raw.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "-Zo8rHBWTlOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data summary\n",
        "print('-'*10, 'data summary', '-'*10)\n",
        "data_raw.describe().toPandas()"
      ],
      "metadata": {
        "id": "DYlL8Hk5Sk-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw_copy = data_raw.select('*')"
      ],
      "metadata": {
        "id": "VDPXbTsrYccn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw_copy = data_raw_copy.where(data_raw.Age65 != '0')\n",
        "data_raw_copy = data_raw_copy.where(data_raw.Gender != '0')"
      ],
      "metadata": {
        "id": "BFyGn2TIf0sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "\n",
        "                    #.withColumn(\"LastSmokedAge\", regexp_replace('LastSmokedAge', '0', '30'))\\\n",
        "                    #.withColumn(\"AvgNumCigADay\", regexp_replace('Smoked100', '0', '2'))\\\n",
        "data_raw_copy = data_raw_copy.withColumn(\"BMI\", regexp_replace('BMI', '0', '2'))\\\n",
        "                    .withColumn(\"GeneralHealth\", regexp_replace('GeneralHealth', '0', '2'))\\\n",
        "                    .withColumn(\"Smoked100\", regexp_replace('Smoked100', '0', '2'))\\\n",
        "                    .withColumn(\"SmokerStatus\", regexp_replace('SmokerStatus', '0', '4'))\\\n",
        "                    .withColumn(\"FirstSmokedAge\", regexp_replace('FirstSmokedAge', '0', '18'))\\\n",
        "                    .withColumn(\"HasCTScan\", regexp_replace('HasCTScan', '0', '2'))\\\n",
        "                    .withColumn(\"StopSmoking\", regexp_replace('StopSmoking', '0', '2'))\\\n",
        "                    .withColumn(\"HasAsthma\", regexp_replace('HasAsthma', '0', '2'))\\\n",
        "                    .withColumn(\"HasChronicDisease\", regexp_replace('HasChronicDisease', '0', '2'))"
      ],
      "metadata": {
        "id": "wlqLL-QCe5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw_copy.columns if data_raw_copy.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw_copy.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "dJEbAklKaHxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw.columns if data_raw.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "VM34527llA5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw.columns if data_raw.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category=temp_col.orderBy(\n",
        "                     temp_col['count'].desc()).collect()[0][0]\n",
        "    data_raw = data_raw.replace(frequent_category, subset=col_)\n",
        "data_raw.show()"
      ],
      "metadata": {
        "id": "bEdqlAECjanv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.write.option(\"header\",True).csv(\"final_data\")"
      ],
      "metadata": {
        "id": "z3SdUg_bX0tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Decision Tree Classification with PySpark"
      ],
      "metadata": {
        "id": "ub67FIvzs5vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process categorical columns\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer, BucketedRandomProjectionLSH,VectorSlicer\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.linalg import Vectors,VectorUDT\n",
        "from pyspark.sql.functions import array, create_map, struct\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# categorical columns\n",
        "categorical_columns = data_raw.columns[0:12]"
      ],
      "metadata": {
        "id": "0PHTGS3G8FLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build StringIndexer stages\n",
        "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='strindexed_' + c) for c in categorical_columns]\n",
        "# encode label column and add it to stringindexer_stages\n",
        "stringindexer_stages += [StringIndexer(inputCol='HasLungCancer', outputCol='label')]"
      ],
      "metadata": {
        "id": "9b83GKwjBWrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build OneHotEncoder stages\n",
        "onehotencoder_stages = [OneHotEncoder(inputCol='strindexed_' + c, outputCol='onehot_' + c) for c in categorical_columns]"
      ],
      "metadata": {
        "id": "aJyA-6l9Bajq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build VectorAssembler stage\n",
        "feature_columns = ['onehot_' + c for c in categorical_columns]\n",
        "vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol='features') "
      ],
      "metadata": {
        "id": "LzJTtiGeBeqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build Pipeline model\n",
        "# all stages\n",
        "all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
        "pipeline = Pipeline(stages=all_stages)"
      ],
      "metadata": {
        "id": "tC1kr4rUB-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit pipeline model\n",
        "pipeline_model = pipeline.fit(data_raw)"
      ],
      "metadata": {
        "id": "bp3Yj3uQBguI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transform data\n",
        "final_columns = feature_columns + ['features', 'label']\n",
        "df_raw = pipeline_model.transform(data_raw).\\\n",
        "            select(final_columns)\n",
        "            \n",
        "df_raw.show(5)"
      ],
      "metadata": {
        "id": "f8k_MQ5aB_aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split data into traning and test sets\n",
        "training, test = df_raw.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "dywcNlfzBmFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@title Data Imputing\n",
        "#    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n",
        "#    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
        "#).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "uBdTvD8K1wH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.printSchema() #'onehot_SEXVAR', 'onehot__AGE65YR', 'onehot__BMI5CAT', 'onehot_GENHLTH',\n",
        "                       #     'onehot_SMOKE100', 'onehot__SMOKER3', 'onehot_LCSFIRST', 'onehot_LCSLAST',\n",
        "                       #     'onehot_LCSNUMCG', 'onehot_LCSCTSCN', 'onehot_STOPSMK2', 'onehot_ASTHMA3', "
      ],
      "metadata": {
        "id": "42qiFRVy49LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data balancing using SMOTE\n",
        "#K-nearest neighbor algorithm to simulate the minority sample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "features = training.select(['features']).toPandas()\n",
        "\n",
        "labels = training.select('label').toPandas()"
      ],
      "metadata": {
        "id": "djvCj8i5439U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(sampling_strategy = 'not majority', k_neighbors = 50, random_state = 42)\n",
        "\n",
        "features, labels = sm.fit_resample(features, labels)"
      ],
      "metadata": {
        "id": "cw74cJ3LMnY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['label'] = labels.values\n",
        "features = spark.createDataFrame(features)"
      ],
      "metadata": {
        "id": "AqpukeY159CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build cross validation \n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')"
      ],
      "metadata": {
        "id": "qwlu-9rjCSQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parameter grid\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder().\\\n",
        "    addGrid(dt.maxDepth, [2,3,4,5]).\\\n",
        "    build()"
      ],
      "metadata": {
        "id": "ZuREkLzgD6Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
      ],
      "metadata": {
        "id": "yW2VQAJKG6XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cross-validation model\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator=dt, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
      ],
      "metadata": {
        "id": "v7kKnG8iG6-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit cross validation model\n",
        "cv_model = cv.fit(df_raw)"
      ],
      "metadata": {
        "id": "3DzaANdoG9hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']"
      ],
      "metadata": {
        "id": "jao_fUI9HHwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prediction on training data\n",
        "pred_training_cv = cv_model.transform(training)\n",
        "pred_training_cv.select(show_columns).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "kwGsJiVKHLrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prediction on test data\n",
        "pred_test_cv = cv_model.transform(test)\n",
        "pred_test_cv.select(show_columns).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "6u9U-X7DHQXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion matrix\n",
        "label_and_pred = cv_model.transform(df_raw).select('label', 'prediction')\n",
        "label_and_pred.rdd.zipWithIndex().countByKey()"
      ],
      "metadata": {
        "id": "pMlMaoENHXE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best MaxDepth is:', cv_model.bestModel._java_obj.getMaxDepth())"
      ],
      "metadata": {
        "id": "sedo-bSOJpKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}