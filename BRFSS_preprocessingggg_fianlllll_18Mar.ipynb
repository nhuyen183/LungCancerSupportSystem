{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QgiznxMrt7FNMiBrsW6duF1SsDt_Y02k",
      "authorship_tag": "ABX9TyNnCb0lWkKBMeit/H5lLPSb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhuyen183/LungCancerSupportSystem/blob/master/BRFSS_preprocessingggg_fianlllll_18Mar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxvbCvWzF2iN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22caaa5-5362-4a53-e5ef-a3472d0d1929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [920 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,544 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,021 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,017 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,313 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,398 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,136 kB]\n",
            "Fetched 12.7 MB in 4s (3,190 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "#@title Installing Spark and dependencies\n",
        "#Java 8\n",
        "#Apache Spark with hadoop and\n",
        "#Findspark (used to locate the spark in the system)\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "#Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Define the problem\n",
        "What sorts of people were likely to have lung cancer?"
      ],
      "metadata": {
        "id": "yZQ9Ioxnrn8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Gather the data\n",
        "The datasets can be found here:\n",
        "* https://www.kaggle.com/datasets/aemreusta/brfss-2020-survey-data\n",
        "* https://www.kaggle.com/datasets/sakinak/behavioral-risk-factor-surveillance-survey-201619"
      ],
      "metadata": {
        "id": "bc9uZc0_r0rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Spark entry points\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "c6udoYI94hjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext(conf=SparkConf())\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "metadata": {
        "id": "UJAvHSw3_PY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Spark Mlib libraries\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier"
      ],
      "metadata": {
        "id": "7U1wvI6hSJ1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Prepare data for consumption"
      ],
      "metadata": {
        "id": "Iqd2fYf8sANz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount content to drive for kaggle data download\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f0oAl82IKAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "TKKEiZnQ_Opq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "HMOTjRHtKNzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "iZsjMEFPMwt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "1hVTxodyKaZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download aemreusta/brfss-2020-survey-data"
      ],
      "metadata": {
        "id": "iwQZmM_OLlfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download sakinak/behavioral-risk-factor-surveillance-survey-201619"
      ],
      "metadata": {
        "id": "B3TqFy7SlblE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Agbrey1YNwLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip brfss-2020-survey-data.zip"
      ],
      "metadata": {
        "id": "iOsR2nmcOFtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip behavioral-risk-factor-surveillance-survey-201619.zip"
      ],
      "metadata": {
        "id": "tHtnFSMplmq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import check_output\n",
        "print('-'*10, 'Files', '-'*10)\n",
        "print(check_output(['ls', './']).decode('utf8'))"
      ],
      "metadata": {
        "id": "Hay7kOmrSQU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the BRFSS dataset and Prediction task\n",
        "\n",
        "The Behavioral Risk Factor Surveillance System (BRFSS) is a collaborative project between all of the states in the United States and participating US territories and the Centers for Disease Control and Prevention (CDC).\n",
        "\n",
        "BRFSS’s objective is to collect uniform state-specific data on health risk behaviors, chronic diseases and conditions, access to health care, and use of preventive health services related to the leading causes of death and disability in the United States. BRFSS conducts both landline and mobile phone-based surveys with individuals over the age of 18. General factors assessed by the BRFSS in 2020 included health status and healthy days, exercise, insufficient sleep, chronic health conditions, oral health, tobacco use, cancer screenings, and access to healthcare.\n",
        "\n",
        "The aim of this project is to build a model with relatively high accuracy and AUC that could serve as an decision aid for those at high risk of developing lung cancer.\n",
        "\n",
        "The data contains information about 401958 unique survey participant. As a result of my research to select the ones related to coronary artery disease among a total of 279 different features. Each example in the dataset contains the following demographic data for a set of individuals\n",
        "\n",
        "### Categorical Features\n",
        "*   `_AGE65YR`: The age of the individual in years two-level categories `18 <= AGE <= 64`: `1` and `65 <= AGE <= 99`:`2`\n",
        "*   `SEXVAR`: Sex of Respondent `Male: 1` and `Female: 2`\n",
        "*   `_BMI5CAT`:  Four-categories of Body Mass Index (BMI)`_BMI5 < 1850: Underweight` ; `1850 <= _BMI5 < 2500: Normal`;`2500 <= _BMI5 < 3000: Overweight`;`3000 <= _BMI5 < 9999: Obese`\n",
        "*   `GENHLTH`: Health status: Would you say that in general your health is: `1: Excellent`; `2: Very good` ; `3: Good` ; `4: Fair` ; `5: Poor`\n",
        "*   `SMOKE100`: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] `1: Yes` ; `2: No`\n",
        "*   `_SMOKER3`: Four-level smoker status: Everyday smoker: `1`, Someday smoker: `2`, Former smoker: `3`, Non-smoker: `4`\n",
        "\n",
        "### Lung Cancer (Features) Screening Section\n",
        "*   `LCSFIRST`: How old were you when you first started to smoke cigarettes regularly. `Value 1-100 in years`\n",
        "*   `LCSLAST`: How old were you when you last smoked cigarettes regularly? `Value 1-100 in years`\n",
        "*   `LCSNUMCG`: On average, when you smoke/smoked regularly, about how many cigarettes do/did you usually smoke each \n",
        "day? `Value 1-300 in number of cigarettes`\n",
        "*   `LCSCTSCN`: In the last 12 months, did you have a CT or CAT scan? Example include: `Yes, to check for lung cancer`, `No (did not have a CT scan`, `Had a CT scan, but for other reason`.\n",
        "*   `CNCRTYP1`:  What type of cancer was it? (If Response = 2 (Two) or 3 (Three or more), ask: “With your most recent \n",
        "diagnoses of cancer, what type of cancer was it?”). Examples include: `Lung cancer: 24`, `Others: 1-30`\n",
        "*   `STOPSMK2`:  During the past 12 months, have you stopped smoking for one day or longer because you were trying to quit smoking? `Yes: 1` or `No: 2`.\n",
        "*   `ECIGARET`: Have you ever used an e-cigarette or other electronic vaping product, even just one time, in your entire life? `Yes: 1` or `No: 2`.\n",
        "*   `ECIGNOW`: Do you now use e-cigarettes or other electronic vaping products every day, some days, or not at all? `Every day: 1`; `Some days: 2` or `Not at all: 3`\n",
        "* `ASTHMA3`: (Ever told) (you had) asthma? `Yes: 1` or `No: 2`.\n",
        "### Prediction Task\n",
        "The prediction task is to **early predict whether a person have the high risk of lung cancer.**\n",
        "\n",
        "### Label\n",
        "*   `CNCRTYP1`: What type of cancer (lung cancer = 24)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FU9ICs1C3_i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "from google.colab import widgets\n",
        "# For facets\n",
        "from IPython.core.display import display, HTML\n",
        "import base64\n",
        "!pip install facets-overview==1.0.0\n",
        "from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator"
      ],
      "metadata": {
        "id": "AIaSSnM5G8kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load packages\n",
        "import sys\n",
        "print('Python version: {}'. format(sys.version))\n",
        "\n",
        "import pandas as pd\n",
        "print('Python version: {}'. format(pd.__version__))\n",
        "\n",
        "import matplotlib\n",
        "print('matplotlib version: {}'. format(matplotlib.__version__))\n",
        "\n",
        "import numpy as np\n",
        "print('numpy version: {}'. format(np.__version__))\n",
        "\n",
        "import scipy as sp\n",
        "print('scipy version: {}'. format(sp.__version__))\n",
        "\n",
        "import IPython\n",
        "from IPython import display # pretty printing of dataframe in Jupyter notebook\n",
        "print('IPython version: {}'. format(IPython.__version__))\n",
        "\n",
        "import pyspark\n",
        "print('Apache Spark Pyspark version: {}'. format(pyspark.__version__)) # pyspark version\n",
        "\n",
        "# misc libraries\n",
        "import random\n",
        "import time\n",
        "\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print('-'*25)"
      ],
      "metadata": {
        "id": "4SvIs_HXORO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "data_2020 = spark.read.csv('./brfss2020.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2020.dtypes)"
      ],
      "metadata": {
        "id": "es2VmY2VSUD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F = data_2020.select('SEXVAR', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'CHECKUP1', #frequency of checkup\n",
        "                              'EXERANY2', #Exercise in Past 30 Days\n",
        "                              'SMOKE100', '_SMOKER3',\n",
        "                              'STOPSMK2', #try to quit smoking\n",
        "                              'LASTSMK2',#time since quitting\n",
        "                              #'LCSFIRST', 'LCSLAST', 'LCSNUMCG',\n",
        "                              'ECIGARET', 'ECIGNOW',\n",
        "                              'LCSCTSCN',\n",
        "                              'CHCCOPD2',\n",
        "                   'ASTHMA3','CVDSTRK3', #ever had a stroke\n",
        "                              'CVDCRHD4', #Ever Diagnosed with Angina or Coronary Heart Disease\n",
        "                              'CNCRTYP1')\n",
        "data_2020F.show()"
      ],
      "metadata": {
        "id": "a59eVrl_rXpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2020F = data_2020F.withColumn(\"SEXVAR\", col('SEXVAR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHECKUP1\", col('CHECKUP1').cast(IntegerType()))\\\n",
        "          .withColumn(\"EXERANY2\", col('EXERANY2').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "          .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"LASTSMK2\", col('LASTSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))\\\n",
        "          .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHCCOPD2\", col('CHCCOPD2').cast(IntegerType()))\\\n",
        "          .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDSTRK3\", col('CVDSTRK3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDCRHD4\", col('CVDCRHD4').cast(IntegerType()))\\\n",
        "          .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "UHcJLziUEndi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#401958\n",
        "data_2020F = data_2020F.na.drop(how='any', thresh=None, subset=(\"GENHLTH\", \"CHECKUP1\", \"EXERANY2\", \"SMOKE100\", \"CVDSTRK3\", \"CVDCRHD4\", \"CHCCOPD2\"))#\"_BMI5CAT\", , \"ASTHMA3\", \"CHCCOPD2\", \"LCSFIRST\",\"LCSLAST\",\"LCSNUMCG\",\"LCSCTSCN\", \"LASTSMK2\", \"STOPSMK2\", \"ECIGNOW\"))\n",
        "data_2020F.count()"
      ],
      "metadata": {
        "id": "PhbNw7X-Uj9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2020F.select([eval('data_2020F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2020F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "VIXjj0pdAXSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.filter(data_2020F.CNCRTYP1 ==24.0).count()"
      ],
      "metadata": {
        "id": "B4WvXkivYdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.count()"
      ],
      "metadata": {
        "id": "oJ69yRpnUyKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020F.printSchema"
      ],
      "metadata": {
        "id": "R-U64hlaC_Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: 1 if y == 24 else 0, StringType())\n",
        "\n",
        "\n",
        "x_age = udf(lambda x: 0 if (x==1 or x==3) else 1, StringType())\n",
        "x_bmi = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4) else 2, StringType())\n",
        "x_health = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4 or x==5) else 0, StringType())\n",
        "x_checkup = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4 or x==8) else 0, StringType())\n",
        "x_smoke3 = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4) else 4, StringType())\n",
        "x_lastsmk = udf(lambda x: x if (x==1 or x==2 or x==3 or x==4 or x==5 or x==6 or x==7 or x==8) else 0, StringType())\n",
        "x_ecig = udf(lambda x: x if (x==1 or x==2 or x==3) else 0, StringType())\n",
        "x_CT = udf(lambda x: x if (x==1 or x==3) else 0, StringType())\n",
        "x_bool = udf(lambda x: 1 if (x==1) else 0, StringType())\n",
        "\n",
        "processed_2020 = data_2020F.withColumn(\"Gender\", x_bool('SEXVAR')).drop(\"SEXVAR\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"CheckupFreq\", x_checkup('CHECKUP1')).drop(\"CHECKUP1\")\\\n",
        "                    .withColumn(\"Exercise\", x_bool('EXERANY2')).drop(\"EXERANY2\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"TimeSinceQuitSmk\", x_smoke3('LASTSMK2')).drop(\"LASTSMK2\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD2')).drop(\"CHCCOPD2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HadStroke\", x_bool('CVDSTRK3')).drop(\"CVDSTRK3\")\\\n",
        "                    .withColumn(\"HadHeartDisease\", x_bool('CVDCRHD4')).drop(\"CVDCRHD4\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")"
      ],
      "metadata": {
        "id": "eDAVhS70Eyfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.groupBy(processed_2020.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "flLjDFqKFksT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.show()"
      ],
      "metadata": {
        "id": "uzq9-ilF8ydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.count()"
      ],
      "metadata": {
        "id": "JPHiGP__GQN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "RQLWe9R0FcXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020 = imputer.fit(processed_2020).transform(processed_2020)"
      ],
      "metadata": {
        "id": "p5wiIyQSKHcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.show(5)"
      ],
      "metadata": {
        "id": "Mrza-rVrKgen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "47G5jrzjJvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2020.write.option(\"header\",True).csv(\"data2020\")"
      ],
      "metadata": {
        "id": "4_Xbra22ND2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 2\n",
        "data_2017 = spark.read.csv('./2017.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2017.dtypes)"
      ],
      "metadata": {
        "id": "fpqW-agTF9SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2017F = data_2017.select('SEX', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'CHECKUP1', #frequency of checkup\n",
        "                              'EXERANY2', #Exercise in Past 30 Days\n",
        "                              'SMOKE100', '_SMOKER3',\n",
        "                              'STOPSMK2', #try to quit smoking\n",
        "                              'LASTSMK2',#time since quitting\n",
        "                              #'LCSFIRST', 'LCSLAST', 'LCSNUMCG',\n",
        "                              'ECIGARET', 'ECIGNOW',\n",
        "                              'LCSCTSCN',\n",
        "                              'CHCCOPD1',\n",
        "                   'ASTHMA3','CVDSTRK3', #ever had a stroke\n",
        "                              'CVDCRHD4', #Ever Diagnosed with Angina or Coronary Heart Disease\n",
        "                              'CNCRTYP1')\n",
        "data_2017F.show(6)"
      ],
      "metadata": {
        "id": "6y-28e5EF9SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#401958\n",
        "#data_2017F = data_2017F.na.drop(how=\"any\")\n",
        "data_2017F.count()"
      ],
      "metadata": {
        "id": "7EY6U960F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2017F = data_2017F.withColumn(\"SEX\", col('SEX').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHECKUP1\", col('CHECKUP1').cast(IntegerType()))\\\n",
        "          .withColumn(\"EXERANY2\", col('EXERANY2').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "          .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"LASTSMK2\", col('LASTSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))\\\n",
        "          .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHCCOPD1\", col('CHCCOPD1').cast(IntegerType()))\\\n",
        "          .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDSTRK3\", col('CVDSTRK3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDCRHD4\", col('CVDCRHD4').cast(IntegerType()))\\\n",
        "          .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "K3swrzG6F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#450016\n",
        "data_2017F = data_2017F.na.drop(how='any', thresh=None, subset=(\"_BMI5CAT\",\"_AGE65YR\", \"GENHLTH\", \"CHECKUP1\", \"EXERANY2\", \"SMOKE100\", \"_SMOKER3\", \"ECIGARET\", \"CHCCOPD1\", \"ASTHMA3\", \"CVDSTRK3\", \"CVDCRHD4\"))#\"_BMI5CAT\",, \"ASTHMA3\", \"CHCCOPD2\", \"LCSFIRST\",\"LCSLAST\",\"LCSNUMCG\",\"LCSCTSCN\", \"LASTSMK2\", \"STOPSMK2\", \"ECIGNOW\"))\n",
        "data_2017F.count()"
      ],
      "metadata": {
        "id": "IgsE7q1Bn_Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2017F.select([eval('data_2017F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2017F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "aV_J-yJ1F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2017F.count()"
      ],
      "metadata": {
        "id": "v4xWm_D-F9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "processed_2017 = data_2017F.withColumn(\"Gender\", x_bool('SEX')).drop(\"SEX\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"CheckupFreq\", x_checkup('CHECKUP1')).drop(\"CHECKUP1\")\\\n",
        "                    .withColumn(\"Exercise\", x_bool('EXERANY2')).drop(\"EXERANY2\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"TimeSinceQuitSmk\", x_smoke3('LASTSMK2')).drop(\"LASTSMK2\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD1')).drop(\"CHCCOPD1\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HadStroke\", x_bool('CVDSTRK3')).drop(\"CVDSTRK3\")\\\n",
        "                    .withColumn(\"HadHeartDisease\", x_bool('CVDCRHD4')).drop(\"CVDCRHD4\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")"
      ],
      "metadata": {
        "id": "aptggGVK2mfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.show()"
      ],
      "metadata": {
        "id": "zYOHNjzL2l84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.groupBy(processed_2017.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "Wfm7DEwC3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "rm7sLfzm3DHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017 = imputer.fit(processed_2017).transform(processed_2017)"
      ],
      "metadata": {
        "id": "zpynWheN3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2017.show(5)"
      ],
      "metadata": {
        "id": "kY2lqtf73DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "eWutDHdG3DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 3\n",
        "data_2018 = spark.read.csv('./2018.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2018.dtypes)"
      ],
      "metadata": {
        "id": "OV3SzAuNI6qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F = data_2018.select('SEX1', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'CHECKUP1', #frequency of checkup\n",
        "                              'EXERANY2', #Exercise in Past 30 Days\n",
        "                              'SMOKE100', '_SMOKER3',\n",
        "                              'STOPSMK2', #try to quit smoking\n",
        "                              'LASTSMK2',#time since quitting\n",
        "                              #'LCSFIRST', 'LCSLAST', 'LCSNUMCG',\n",
        "                              'ECIGARET', 'ECIGNOW',\n",
        "                              'LCSCTSCN',\n",
        "                              'CHCCOPD1',\n",
        "                   'ASTHMA3','CVDSTRK3', #ever had a stroke\n",
        "                              'CVDCRHD4', #Ever Diagnosed with Angina or Coronary Heart Disease\n",
        "                              'CNCRTYP1')\n",
        "data_2018F.show(6)"
      ],
      "metadata": {
        "id": "KvRzP3z5I6rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data_2018F = data_2018F.withColumn(\"SEX1\", col('SEX1').cast(IntegerType()))\\\n",
        "          .withColumn(\"_AGE65YR\", col('_AGE65YR').cast(IntegerType()))\\\n",
        "          .withColumn(\"_BMI5CAT\", col('_BMI5CAT').cast(IntegerType()))\\\n",
        "          .withColumn(\"GENHLTH\", col('GENHLTH').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHECKUP1\", col('CHECKUP1').cast(IntegerType()))\\\n",
        "          .withColumn(\"EXERANY2\", col('EXERANY2').cast(IntegerType()))\\\n",
        "          .withColumn(\"SMOKE100\", col('SMOKE100').cast(IntegerType()))\\\n",
        "          .withColumn(\"_SMOKER3\", col('_SMOKER3').cast(IntegerType()))\\\n",
        "          .withColumn(\"STOPSMK2\", col('STOPSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"LASTSMK2\", col('LASTSMK2').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGARET\", col('ECIGARET').cast(IntegerType()))\\\n",
        "          .withColumn(\"ECIGNOW\", col('ECIGNOW').cast(IntegerType()))\\\n",
        "          .withColumn(\"LCSCTSCN\", col('LCSCTSCN').cast(IntegerType()))\\\n",
        "          .withColumn(\"CHCCOPD1\", col('CHCCOPD1').cast(IntegerType()))\\\n",
        "          .withColumn(\"ASTHMA3\", col('ASTHMA3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDSTRK3\", col('CVDSTRK3').cast(IntegerType()))\\\n",
        "          .withColumn(\"CVDCRHD4\", col('CVDCRHD4').cast(IntegerType()))\\\n",
        "          .withColumn(\"CNCRTYP1\", col('CNCRTYP1').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "coDyK_iDbIyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#437436\n",
        "data_2018F = data_2018F.na.drop(how='any', thresh=None, subset=(\"_BMI5CAT\",\"_AGE65YR\", \"GENHLTH\", \"CHECKUP1\", \"EXERANY2\", \"SMOKE100\", \"_SMOKER3\", \"CHCCOPD1\", \"ASTHMA3\", \"CVDSTRK3\", \"CVDCRHD4\"))#\"_BMI5CAT\",, \"ASTHMA3\", \"CHCCOPD2\", \"LCSFIRST\",\"LCSLAST\",\"LCSNUMCG\",\"LCSCTSCN\", \"LASTSMK2\", \"STOPSMK2\", \"ECIGNOW\"))\n",
        "data_2018F.count()"
      ],
      "metadata": {
        "id": "0e9Ls9mcp0eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2018F.select([eval('data_2018F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2018F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "C6d0Yio_I6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.count()"
      ],
      "metadata": {
        "id": "jhRvkqcUfV_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.printSchema()"
      ],
      "metadata": {
        "id": "2-k2n0j03_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: 1 if y == 24 else 0, StringType())\n",
        "\n",
        "processed_2018 = data_2018F.withColumn(\"Gender\", x_bool('SEX1')).drop(\"SEX1\")\\\n",
        "                    .withColumn(\"Age65\", x_age('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"BMI\", x_bmi('_BMI5CAT')).drop(\"_BMI5CAT\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_health('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"CheckupFreq\", x_checkup('CHECKUP1')).drop(\"CHECKUP1\")\\\n",
        "                    .withColumn(\"Exercise\", x_bool('EXERANY2')).drop(\"EXERANY2\")\\\n",
        "                    .withColumn(\"Smoked100\", x_bool('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_smoke3('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_bool('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"TimeSinceQuitSmk\", x_smoke3('LASTSMK2')).drop(\"LASTSMK2\")\\\n",
        "                    .withColumn(\"EverUsedEcig\", x_bool('ECIGARET')).drop(\"ECIGARET\")\\\n",
        "                    .withColumn(\"EcigLevel\", x_ecig('ECIGNOW')).drop(\"ECIGNOW\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_CT('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_bool('CHCCOPD1')).drop(\"CHCCOPD1\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_bool('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HadStroke\", x_bool('CVDSTRK3')).drop(\"CVDSTRK3\")\\\n",
        "                    .withColumn(\"HadHeartDisease\", x_bool('CVDCRHD4')).drop(\"CVDCRHD4\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "sUNNNGf13_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.show()"
      ],
      "metadata": {
        "id": "9OH3pnWI3e1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.groupBy(processed_2018.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "8fRbxoZG3_MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.write.option(\"header\",True).csv(\"df_test\")"
      ],
      "metadata": {
        "id": "esLz9dmu6oiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.show()"
      ],
      "metadata": {
        "id": "BWSEGR2p3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay'],\n",
        "    outputCols = ['FirstSmokedAge', 'LastSmokedAge', 'AvgNumCigADay']\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "pl69LlHc3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018 = imputer.fit(processed_2018).transform(processed_2018)"
      ],
      "metadata": {
        "id": "TWRpizsx3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2018.show(5)"
      ],
      "metadata": {
        "id": "y5RX2PWp3_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in processed_2020.columns]\n",
        "for col_ in column_subset:\n",
        "    temp_col = processed_2020.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "matqeC9s3_MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#437436\n",
        "data_2018F = data_2018F.na.drop(how=\"any\")\n",
        "data_2018F.count()"
      ],
      "metadata": {
        "id": "4NPPejlaI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.show(6)"
      ],
      "metadata": {
        "id": "dpZZLsdHI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2018F.groupBy(data_2018F.CNCRTYP1==24).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "Y6WQEJZZI6rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data_2018F.filter(data_2018F.CNCRTYP1 == 24)\n",
        "test_data.show()"
      ],
      "metadata": {
        "id": "nfJJf0ejI6rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "df_train= processed_2020.unionByName(processed_2017)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data.dtypes)"
      ],
      "metadata": {
        "id": "8oWD6CAk4exO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.groupBy(df_train.HasLungCancer).count().show()\n"
      ],
      "metadata": {
        "id": "YAFMFMlM4wYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.write.option(\"header\",True).csv(\"df_train\")"
      ],
      "metadata": {
        "id": "5Nbsbtbj4XOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Integration 4\n",
        "data_2019 = spark.read.csv('./2019.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_2019.dtypes)"
      ],
      "metadata": {
        "id": "a0GVWDOuJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F = data_2019.select('SEXVAR', '_AGE65YR', '_BMI5CAT', 'GENHLTH', 'SMOKE100', '_SMOKER3',\n",
        "                  'LCSFIRST', 'LCSLAST', 'LCSNUMCG', 'LCSCTSCN', 'CNCRTYP1',\n",
        "                  'STOPSMK2', 'ASTHMA3', 'CHCCOPD2') #'ECIGARET',  'ECIGNOW'\n",
        "data_2019F.show(6)"
      ],
      "metadata": {
        "id": "3qoKhmNjJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Columns with null values:')\n",
        "print('-'*25)\n",
        "data_2019F.select([eval('data_2019F.' + x + '.isNull().cast(\"int\").alias(\"' + x + '\")') for x in data_2019F.columns]).\\\n",
        "    groupBy().sum().toPandas()"
      ],
      "metadata": {
        "id": "xgu2EkJ6J1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_2019F = data_2019F.na.drop(how=\"any\")\n",
        "data_2019F.count()"
      ],
      "metadata": {
        "id": "7LNr5x_LJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.show(6)"
      ],
      "metadata": {
        "id": "_Pi8ZvtuJ1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.filter(data_2019F.CNCRTYP1 != 'NA').count()"
      ],
      "metadata": {
        "id": "p7YlFDENJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2019F.printSchema()"
      ],
      "metadata": {
        "id": "rNFFkz0uJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title User Defined Functions (UDF) for prediction label\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "y_udf = udf(lambda y: '1' if y == '24' else '0', StringType())\n",
        "x_udf = udf(lambda x: '0' if (x=='NA' or x=='7' or x=='77' or x=='777' or x=='9' or x=='99' or x=='888' or x=='999') else x, StringType())\n",
        "\n",
        "processed_2019 = data_2019F.withColumn(\"Gender\", x_udf('SEXVAR')).drop(\"SEXVAR\")\\\n",
        "                    .withColumn(\"Age65\", x_udf('_AGE65YR')).drop(\"_AGE65YR\")\\\n",
        "                    .withColumn(\"GeneralHealth\", x_udf('GENHLTH')).drop(\"GENHLTH\")\\\n",
        "                    .withColumn(\"Smoked100\", x_udf('SMOKE100')).drop(\"SMOKE100\")\\\n",
        "                    .withColumn(\"SmokerStatus\", x_udf('_SMOKER3')).drop(\"_SMOKER3\")\\\n",
        "                    .withColumn(\"FirstSmokedAge\", x_udf('LCSFIRST')).drop(\"LCSFIRST\")\\\n",
        "                    .withColumn(\"LastSmokedAge\", x_udf('LCSLAST')).drop(\"LCSLAST\")\\\n",
        "                    .withColumn(\"AvgNumCigADay\", x_udf('LCSNUMCG')).drop(\"LCSNUMCG\")\\\n",
        "                    .withColumn(\"HasCTScan\", x_udf('LCSCTSCN')).drop(\"LCSCTSCN\")\\\n",
        "                    .withColumn(\"StopSmoking\", x_udf('STOPSMK2')).drop(\"STOPSMK2\")\\\n",
        "                    .withColumn(\"HasAsthma\", x_udf('ASTHMA3')).drop(\"ASTHMA3\")\\\n",
        "                    .withColumn(\"HasChronicDisease\", x_udf('CHCCOPD2')).drop(\"CHCCOPD2\")\\\n",
        "                    .withColumn(\"HasLungCancer\", y_udf('CNCRTYP1')).drop(\"CNCRTYP1\")\n",
        "                    "
      ],
      "metadata": {
        "id": "AeHO0eHqJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2019.printSchema()"
      ],
      "metadata": {
        "id": "d6_5G06bJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_2019.groupBy(processed_2019.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "398LfjydJ1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "data = processed_2020.unionByName(processed_2017)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data.dtypes)"
      ],
      "metadata": {
        "id": "9Wj7XDTzpcfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw = data.unionByName(processed_2018)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_raw.dtypes)"
      ],
      "metadata": {
        "id": "EtwRGyl3R_hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define schema explitcitly\n",
        "from pyspark.sql.types import *\n",
        "data_raw.columns"
      ],
      "metadata": {
        "id": "w2lEu1Bt9e0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.groupBy(data_raw.HasLungCancer).count().show()\n",
        "# Data is unbalanced :)"
      ],
      "metadata": {
        "id": "-Zo8rHBWTlOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data summary\n",
        "print('-'*10, 'data summary', '-'*10)\n",
        "data_raw.describe().toPandas()"
      ],
      "metadata": {
        "id": "DYlL8Hk5Sk-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw_copy = data_raw.select('*')"
      ],
      "metadata": {
        "id": "VDPXbTsrYccn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw_copy = data_raw_copy.where(data_raw.Age65 != '0')\n",
        "data_raw_copy = data_raw_copy.where(data_raw.Gender != '0')"
      ],
      "metadata": {
        "id": "BFyGn2TIf0sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "\n",
        "                    #.withColumn(\"LastSmokedAge\", regexp_replace('LastSmokedAge', '0', '30'))\\\n",
        "                    #.withColumn(\"AvgNumCigADay\", regexp_replace('Smoked100', '0', '2'))\\\n",
        "data_raw_copy = data_raw_copy.withColumn(\"BMI\", regexp_replace('BMI', '0', '2'))\\\n",
        "                    .withColumn(\"GeneralHealth\", regexp_replace('GeneralHealth', '0', '2'))\\\n",
        "                    .withColumn(\"Smoked100\", regexp_replace('Smoked100', '0', '2'))\\\n",
        "                    .withColumn(\"SmokerStatus\", regexp_replace('SmokerStatus', '0', '4'))\\\n",
        "                    .withColumn(\"FirstSmokedAge\", regexp_replace('FirstSmokedAge', '0', '18'))\\\n",
        "                    .withColumn(\"HasCTScan\", regexp_replace('HasCTScan', '0', '2'))\\\n",
        "                    .withColumn(\"StopSmoking\", regexp_replace('StopSmoking', '0', '2'))\\\n",
        "                    .withColumn(\"HasAsthma\", regexp_replace('HasAsthma', '0', '2'))\\\n",
        "                    .withColumn(\"HasChronicDisease\", regexp_replace('HasChronicDisease', '0', '2'))"
      ],
      "metadata": {
        "id": "wlqLL-QCe5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw_copy = data_raw_copy.filter(data_raw_copy.GeneralHealth !=0)"
      ],
      "metadata": {
        "id": "j_XQ7mfHHxNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw_copy.columns if data_raw_copy.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw_copy.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "dJEbAklKaHxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw.columns if data_raw.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category = temp_col.orderBy(\n",
        "                        temp_col['count'].desc()).show()\n",
        "\n",
        "column_subset"
      ],
      "metadata": {
        "id": "VM34527llA5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_subset = [col_ for col_ in data_raw.columns if data_raw.select(col_).dtypes!=\"string\"]\n",
        "for col_ in column_subset:\n",
        "    temp_col = data_raw.groupBy(col_).count()\n",
        "    temp_col = temp_col.dropna(subset=col_)\n",
        "    frequent_category=temp_col.orderBy(\n",
        "                     temp_col['count'].desc()).collect()[0][0]\n",
        "    data_raw = data_raw.replace(frequent_category, subset=col_)\n",
        "data_raw.show()"
      ],
      "metadata": {
        "id": "bEdqlAECjanv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.write.option(\"header\",True).csv(\"final_data\")"
      ],
      "metadata": {
        "id": "z3SdUg_bX0tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Decision Tree Classification with PySpark"
      ],
      "metadata": {
        "id": "ub67FIvzs5vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process categorical columns\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer, BucketedRandomProjectionLSH,VectorSlicer\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.linalg import Vectors,VectorUDT\n",
        "from pyspark.sql.functions import array, create_map, struct\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# categorical columns\n",
        "categorical_columns = data_raw.columns[0:12]"
      ],
      "metadata": {
        "id": "0PHTGS3G8FLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build StringIndexer stages\n",
        "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='strindexed_' + c) for c in categorical_columns]\n",
        "# encode label column and add it to stringindexer_stages\n",
        "stringindexer_stages += [StringIndexer(inputCol='HasLungCancer', outputCol='label')]"
      ],
      "metadata": {
        "id": "9b83GKwjBWrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build OneHotEncoder stages\n",
        "onehotencoder_stages = [OneHotEncoder(inputCol='strindexed_' + c, outputCol='onehot_' + c) for c in categorical_columns]"
      ],
      "metadata": {
        "id": "aJyA-6l9Bajq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build VectorAssembler stage\n",
        "feature_columns = ['onehot_' + c for c in categorical_columns]\n",
        "vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol='features') "
      ],
      "metadata": {
        "id": "LzJTtiGeBeqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build Pipeline model\n",
        "# all stages\n",
        "all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
        "pipeline = Pipeline(stages=all_stages)"
      ],
      "metadata": {
        "id": "tC1kr4rUB-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit pipeline model\n",
        "pipeline_model = pipeline.fit(data_raw)"
      ],
      "metadata": {
        "id": "bp3Yj3uQBguI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transform data\n",
        "final_columns = feature_columns + ['features', 'label']\n",
        "df_raw = pipeline_model.transform(data_raw).\\\n",
        "            select(final_columns)\n",
        "            \n",
        "df_raw.show(5)"
      ],
      "metadata": {
        "id": "f8k_MQ5aB_aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split data into traning and test sets\n",
        "training, test = df_raw.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "dywcNlfzBmFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@title Data Imputing\n",
        "#    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n",
        "#    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
        "#).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "uBdTvD8K1wH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.printSchema() #'onehot_SEXVAR', 'onehot__AGE65YR', 'onehot__BMI5CAT', 'onehot_GENHLTH',\n",
        "                       #     'onehot_SMOKE100', 'onehot__SMOKER3', 'onehot_LCSFIRST', 'onehot_LCSLAST',\n",
        "                       #     'onehot_LCSNUMCG', 'onehot_LCSCTSCN', 'onehot_STOPSMK2', 'onehot_ASTHMA3', "
      ],
      "metadata": {
        "id": "42qiFRVy49LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data balancing using SMOTE\n",
        "#K-nearest neighbor algorithm to simulate the minority sample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "features = training.select(['features']).toPandas()\n",
        "\n",
        "labels = training.select('label').toPandas()"
      ],
      "metadata": {
        "id": "djvCj8i5439U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(sampling_strategy = 'not majority', k_neighbors = 50, random_state = 42)\n",
        "\n",
        "features, labels = sm.fit_resample(features, labels)"
      ],
      "metadata": {
        "id": "cw74cJ3LMnY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['label'] = labels.values\n",
        "features = spark.createDataFrame(features)"
      ],
      "metadata": {
        "id": "AqpukeY159CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build cross validation \n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')"
      ],
      "metadata": {
        "id": "qwlu-9rjCSQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parameter grid\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder().\\\n",
        "    addGrid(dt.maxDepth, [2,3,4,5]).\\\n",
        "    build()"
      ],
      "metadata": {
        "id": "ZuREkLzgD6Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
      ],
      "metadata": {
        "id": "yW2VQAJKG6XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cross-validation model\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator=dt, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
      ],
      "metadata": {
        "id": "v7kKnG8iG6-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit cross validation model\n",
        "cv_model = cv.fit(df_raw)"
      ],
      "metadata": {
        "id": "3DzaANdoG9hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']"
      ],
      "metadata": {
        "id": "jao_fUI9HHwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prediction on training data\n",
        "pred_training_cv = cv_model.transform(training)\n",
        "pred_training_cv.select(show_columns).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "kwGsJiVKHLrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prediction on test data\n",
        "pred_test_cv = cv_model.transform(test)\n",
        "pred_test_cv.select(show_columns).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "6u9U-X7DHQXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion matrix\n",
        "label_and_pred = cv_model.transform(df_raw).select('label', 'prediction')\n",
        "label_and_pred.rdd.zipWithIndex().countByKey()"
      ],
      "metadata": {
        "id": "pMlMaoENHXE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best MaxDepth is:', cv_model.bestModel._java_obj.getMaxDepth())"
      ],
      "metadata": {
        "id": "sedo-bSOJpKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}